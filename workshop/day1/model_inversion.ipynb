{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dnn_utils import *\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### CONSTANTS DEFINING THE MODEL ####\n",
    "n_x = 12288     # num_px * num_px * 3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a two-layer neural network: LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (n_x, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- If set to True, this will print the cost every 100 iterations \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary containing W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost\n",
    "    m = X.shape[1]                           # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1\". Output: \"A1, cache1, A2, cache2\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, \"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, \"sigmoid\")\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Compute cost\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        cost =  compute_cost(A2, Y)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Initializing backward propagation\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, \"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, \"relu\")\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (approx. 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Retrieve W1, b1, W2, b2 from parameters\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "       \n",
    "    # plot the cost\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "\n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "\n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A, cache = linear_activation_forward(A_prev, \n",
    "                                             parameters['W' + str(l)], \n",
    "                                             parameters['b' + str(l)], \n",
    "                                             activation='relu')\n",
    "        caches.append(cache)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    AL, cache = linear_activation_forward(A, \n",
    "                                          parameters['W' + str(L)], \n",
    "                                          parameters['b' + str(L)], \n",
    "                                          activation='sigmoid')\n",
    "    caches.append(cache)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #print(AL.shape, (2, X.shape[1]) )\n",
    "    assert(AL.shape == (2, X.shape[1]))\n",
    "            \n",
    "    return AL, caches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#layers_dims = [12288, 20, 7, 5, 1] #  5-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization.\n",
    "    ### START CODE HERE ###\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Compute cost.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "        # Backward propagation.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        ### END CODE HERE ###\n",
    " \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_train = predict(train_x, train_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generate Training Data\n",
    "\n",
    "xe = l1 cos(theta1)  + l2 cos(theta1 + theta2) + l3 cos(theta1 + theta2 + theta3)\n",
    "\n",
    "ye = l1 sin(theta1) + l2 sin(theta1 + theta2) + l3 sin(theta1 + theta2 + theta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_XY_pair(l1,l2,l3, theta1, theta2, theta3):\n",
    "    \"\"\"\n",
    "    Generates a pair of X and Y on provided angles of the robotic arm\n",
    "    \n",
    "    Arguments:\n",
    "    l1 -- length of first arm\n",
    "    l2 -- length of second arm\n",
    "    l3 -- length of third arm\n",
    "    theta1 -- angle from base of first arm\n",
    "    theta2 -- angle from base of second arm\n",
    "    theta3 -- angle from base of third arm\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    xe = l1 * np.cos(theta1) + l2 * np.cos(theta1 + theta2) + l3 * np.cos(theta1 + theta2 + theta3)\n",
    "    ye = l1 * np.sin(theta1) + l2 * np.sin(theta1 + theta2) + l3 * np.sin(theta1 + theta2 + theta3)\n",
    "    return (xe,ye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angles are 3.114458610918616 3.1038001966267164 3.171781584994252\n",
      "X and Y are -2.00203599822 0.00156067324082\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#test the generate_XY_pair\n",
    "l1 = 1\n",
    "l2 = 2\n",
    "l3 = 3\n",
    "\n",
    "std_dev = 0.1\n",
    "\n",
    "theta1 = np.pi + np.random.randn() * std_dev\n",
    "theta2 = np.pi + np.random.randn() * std_dev\n",
    "theta3 = np.pi + np.random.randn() * std_dev\n",
    "\n",
    "x,y = generate_XY_pair(l1,l2,l3,theta1,theta2,theta3)\n",
    "print(\"angles are\", theta1, theta2, theta3)\n",
    "print(\"X and Y are\", x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets generate 10000 records\n",
    "\n",
    "increment = 0.1\n",
    "no_of_records = 10000\n",
    "\n",
    "data=[]\n",
    "\n",
    "theta1=theta2=theta3=-np.pi\n",
    "\n",
    "for i in range(0, 70):\n",
    "    #print(i)\n",
    "    if theta1 < np.pi:\n",
    "        theta1 +=increment\n",
    "        theta2=theta3=-np.pi\n",
    "        for j in range(0, 70):\n",
    "            if theta2 < np.pi:\n",
    "                theta2 +=increment\n",
    "                theta3=-np.pi\n",
    "                for k in range(0,70):\n",
    "                    if theta3 < np.pi:\n",
    "                        theta3 +=increment\n",
    "                        data.append([theta1,theta2,theta3])\n",
    "\n",
    "#theta1 = np.pi + np.random.randn(no_of_records) * std_dev\n",
    "#theta2 = np.pi + np.random.randn(no_of_records) * std_dev\n",
    "#theta3 = np.pi + np.random.randn(no_of_records) * std_dev\n",
    "\n",
    "\n",
    "\n",
    "l1 = np.zeros(len(data)) + 1\n",
    "l2 = np.zeros(len(data)) + 2\n",
    "l3 = np.zeros(len(data)) + 3\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.04159265, -3.04159265, -3.04159265],\n",
       "       [-3.04159265, -3.04159265, -2.94159265],\n",
       "       [-3.04159265, -3.04159265, -2.84159265],\n",
       "       ..., \n",
       "       [ 3.15840735,  3.15840735,  2.95840735],\n",
       "       [ 3.15840735,  3.15840735,  3.05840735],\n",
       "       [ 3.15840735,  3.15840735,  3.15840735]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250047\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "\n",
    "x,y = generate_XY_pair(l1,l2,l3,data[:,0],data[:,1],data[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.87074978, -1.14077137, -1.39642218, -1.63514782, -1.85456303,\n",
       "       -2.05247548, -2.22690771, -2.37611684, -2.49861201])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:10]\n",
    "y[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " values are 5.99793154915 5.9977765609 -5.99754847696 -5.99624414369\n",
      "[-0.29982052 -0.27807311 -0.2519398  -0.22168168 -0.18760111 -0.15003859\n",
      " -0.10936944 -0.06600001 -0.02036364]\n"
     ]
    }
   ],
   "source": [
    "#scale the x and y as min-max scaling\n",
    "\n",
    "x_max = np.max(x)\n",
    "x_min = np.min(x)\n",
    "\n",
    "y_max = np.max(y)\n",
    "y_min = np.min(y)\n",
    "print(\" values are\", x_max, y_max, x_min, y_min)\n",
    "\n",
    "#scale it\n",
    "x_norm = 2 * ((x - x_min)/ (x_max-x_min)) - 1\n",
    "y_norm = 2 * ((y - y_min) / (y_max - y_min)) - 1\n",
    "\n",
    "print(x_norm[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_x = np.column_stack((theta1,theta2,theta3)).T\n",
    "train_x = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 250047)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = np.column_stack((x_norm,y_norm)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 250047)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_dims = [3, 10, 20, 10, 2] #  5-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.386295\n",
      "Cost after iteration 100: 0.991088\n",
      "Cost after iteration 200: 0.745620\n",
      "Cost after iteration 300: 0.586019\n",
      "Cost after iteration 400: 0.476944\n",
      "Cost after iteration 500: 0.398939\n",
      "Cost after iteration 600: 0.340940\n",
      "Cost after iteration 700: 0.296374\n",
      "Cost after iteration 800: 0.261168\n",
      "Cost after iteration 900: 0.232694\n",
      "Cost after iteration 1000: 0.209195\n",
      "Cost after iteration 1100: 0.189463\n",
      "Cost after iteration 1200: 0.172643\n",
      "Cost after iteration 1300: 0.158116\n",
      "Cost after iteration 1400: 0.145424\n",
      "Cost after iteration 1500: 0.134224\n",
      "Cost after iteration 1600: 0.124254\n",
      "Cost after iteration 1700: 0.115312\n",
      "Cost after iteration 1800: 0.107239\n",
      "Cost after iteration 1900: 0.099909\n",
      "Cost after iteration 2000: 0.093223\n",
      "Cost after iteration 2100: 0.087098\n",
      "Cost after iteration 2200: 0.081470\n",
      "Cost after iteration 2300: 0.076282\n",
      "Cost after iteration 2400: 0.071488\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKQbBYOIiHTz/wHKPrui7V4aVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a07c128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True,learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.0177994 ,  0.00426454,  0.000934  ],\n",
       "        [-0.01896168, -0.00296312, -0.00359468],\n",
       "        [-0.00085928, -0.0063077 , -0.00043228],\n",
       "        [-0.00503953, -0.01329157,  0.00890885],\n",
       "        [ 0.00875989,  0.01705744,  0.00049753],\n",
       "        [-0.00412212, -0.0054819 , -0.01547433],\n",
       "        [ 0.00985497, -0.01099701, -0.01186139],\n",
       "        [-0.00201888,  0.01492457,  0.00237502],\n",
       "        [-0.0102983 , -0.00717661,  0.00623851],\n",
       "        [-0.00162964, -0.00764539, -0.00227443]]),\n",
       " 'W2': array([[  7.45017086e-03,   1.97225393e-02,  -1.24464765e-02,\n",
       "          -6.29140961e-03,  -8.03782535e-03,  -2.41942840e-02,\n",
       "          -9.23798278e-03,  -1.02437895e-02,   1.12073176e-02,\n",
       "          -1.32487834e-03],\n",
       "        [ -1.62328981e-02,   6.48107218e-03,  -3.56268503e-03,\n",
       "          -1.74314196e-02,  -5.96927658e-03,  -5.87463447e-03,\n",
       "          -8.73862591e-03,   2.98777424e-04,  -2.24811641e-02,\n",
       "          -2.67732484e-03],\n",
       "        [  1.01123652e-02,   8.51874484e-03,   1.10803096e-02,\n",
       "           1.11829434e-02,   1.48464797e-02,  -1.11824285e-02,\n",
       "           8.46329357e-03,  -1.86221832e-02,  -6.04148990e-03,\n",
       "          -1.91466387e-02],\n",
       "        [  1.05331383e-02,   1.34428653e-02,  -1.95373201e-03,\n",
       "           1.78033554e-02,  -6.68707169e-03,   1.56187720e-03,\n",
       "           1.55345570e-03,  -1.06054784e-02,   4.44596276e-03,\n",
       "           1.94186454e-02],\n",
       "        [ -1.02484244e-02,   8.99703248e-03,  -1.54446576e-03,\n",
       "           1.76972002e-02,   4.83905272e-03,   6.76404319e-03,\n",
       "           6.43137311e-03,   2.49128136e-03,  -1.39562379e-02,\n",
       "           1.39176189e-02],\n",
       "        [ -1.37070213e-02,   2.37181035e-03,   6.13962360e-03,\n",
       "          -8.37925457e-03,   1.44883560e-03,   1.16599119e-02,\n",
       "          -2.48653034e-04,  -8.89036349e-03,  -2.91578788e-02,\n",
       "          -9.72114464e-03],\n",
       "        [ -5.91637464e-03,  -5.16875965e-03,  -9.61028336e-03,\n",
       "           3.75996309e-03,  -5.74713057e-03,  -1.11519084e-03,\n",
       "           6.75760418e-03,  -8.55437201e-03,  -3.00813318e-03,\n",
       "           2.15676785e-02],\n",
       "        [  8.69402341e-03,  -1.29365876e-02,  -7.98689030e-04,\n",
       "           5.63952747e-03,   1.22844083e-02,   1.48786595e-03,\n",
       "          -5.31684734e-03,  -7.32714282e-03,   6.44769194e-03,\n",
       "           3.12937257e-03],\n",
       "        [ -5.16224516e-03,  -1.89817331e-03,  -4.16661789e-03,\n",
       "           7.24076602e-03,  -6.89965434e-03,   4.84887036e-03,\n",
       "           8.50411270e-03,   4.86181074e-03,  -8.34714290e-03,\n",
       "           1.34429171e-02],\n",
       "        [ -6.78235000e-03,   4.24753160e-03,  -7.53341372e-03,\n",
       "          -1.74411126e-02,   2.25480732e-03,   2.85764902e-03,\n",
       "          -7.75039436e-04,   2.75249530e-03,  -6.48556812e-03,\n",
       "          -7.37500819e-03],\n",
       "        [ -1.60893650e-03,   1.92568409e-02,   8.17718534e-03,\n",
       "          -5.11429010e-03,   5.68169418e-03,  -4.70170602e-03,\n",
       "          -4.54386111e-03,   8.65788224e-03,  -5.14985873e-03,\n",
       "          -1.67153787e-02],\n",
       "        [ -8.97815408e-03,   1.07699149e-03,   1.31668656e-03,\n",
       "           1.25215460e-02,  -7.05549447e-03,   7.41368024e-03,\n",
       "           4.30092530e-03,  -1.42275596e-03,   8.48184964e-03,\n",
       "           4.97257254e-03],\n",
       "        [ -8.62307488e-03,   1.06963019e-02,  -1.22117617e-02,\n",
       "           5.86094470e-04,   2.54024137e-05,   4.23799426e-03,\n",
       "          -7.25571173e-03,  -3.50685711e-04,  -1.41875741e-03,\n",
       "           9.96716943e-03],\n",
       "        [ -7.93303781e-03,   7.56889182e-04,  -2.61088281e-03,\n",
       "          -1.29761798e-02,   2.67883203e-02,  -6.97690319e-04,\n",
       "          -1.48636743e-02,   1.41050179e-02,  -1.06960175e-02,\n",
       "           3.71168315e-03],\n",
       "        [  8.61213327e-03,  -6.48452788e-03,  -4.30907436e-03,\n",
       "          -5.40397383e-03,  -1.30792866e-03,  -1.62246171e-02,\n",
       "          -1.23575697e-02,  -1.41351508e-03,   1.03889439e-02,\n",
       "           6.31730072e-03],\n",
       "        [  1.72894120e-02,   6.91994577e-03,  -5.11343075e-03,\n",
       "          -1.24392253e-03,  -2.03053291e-02,  -9.60861521e-03,\n",
       "          -1.02043990e-02,   2.70057122e-03,   6.46075263e-03,\n",
       "          -5.60554754e-03],\n",
       "        [ -5.86880746e-03,  -1.54674347e-02,  -1.27620111e-03,\n",
       "           2.48201042e-03,   4.47559250e-03,  -7.82379563e-03,\n",
       "           1.98903038e-02,   1.19562324e-02,  -9.52052639e-04,\n",
       "          -5.26936206e-03],\n",
       "        [ -3.21535745e-03,   1.52152553e-03,  -1.84674187e-04,\n",
       "           4.84065903e-03,   7.69290622e-03,   1.36670916e-02,\n",
       "           1.14736225e-02,  -1.09760999e-03,   3.88894929e-03,\n",
       "          -3.86912795e-03],\n",
       "        [ -5.78875393e-03,   1.92768695e-02,  -4.56623276e-03,\n",
       "           1.99991003e-02,  -3.39066819e-03,   2.61593943e-03,\n",
       "           1.09322808e-02,   3.01567332e-04,   4.03861672e-03,\n",
       "          -2.36849218e-03],\n",
       "        [ -4.74998598e-03,  -1.62625477e-03,  -6.49194241e-03,\n",
       "           1.63289479e-02,  -1.67117641e-03,   1.72410160e-02,\n",
       "          -2.68472841e-02,   1.91278197e-04,   5.63746752e-03,\n",
       "          -2.93099494e-03]]),\n",
       " 'W3': array([[ 0.0109465 ,  0.00639692, -0.00274605,  0.00434907,  0.02811828,\n",
       "          0.00251995,  0.00299499, -0.00439994,  0.0013348 , -0.01289262,\n",
       "         -0.00198352,  0.02457481,  0.01067198,  0.00641416,  0.01103921,\n",
       "          0.01881753,  0.00593586,  0.0207083 ,  0.01069671,  0.00166495],\n",
       "        [ 0.01719475, -0.02359215, -0.0057135 ,  0.00265775, -0.00912095,\n",
       "         -0.00156058, -0.00638795, -0.00654416,  0.02711918,  0.00627474,\n",
       "         -0.00053954,  0.01315139, -0.00237334,  0.00885339,  0.00350816,\n",
       "          0.01626573, -0.01419891,  0.00765714,  0.0012223 , -0.01157377],\n",
       "        [ 0.01065403, -0.00872374,  0.01619287,  0.0051359 ,  0.0069585 ,\n",
       "          0.00080459,  0.00904523, -0.01865655,  0.00074738, -0.00628247,\n",
       "          0.00282815, -0.0004704 ,  0.00616827, -0.0083763 ,  0.01839152,\n",
       "          0.0231584 , -0.00208298, -0.00014717,  0.00287883,  0.01264124],\n",
       "        [ 0.01896901, -0.01205803, -0.00615109, -0.01062156, -0.01112782,\n",
       "         -0.01639296,  0.00362803, -0.01159037,  0.01503262,  0.00908318,\n",
       "         -0.01029711, -0.01030209, -0.00612385,  0.01399962, -0.00849607,\n",
       "         -0.0149355 , -0.00049425,  0.00373389, -0.00657258,  0.01619431],\n",
       "        [ 0.00243221,  0.00453336, -0.00850368,  0.00023569, -0.00141475,\n",
       "         -0.02271918,  0.00288258, -0.01793993, -0.00025774, -0.01473489,\n",
       "          0.02093653,  0.00407214,  0.00865802,  0.00936255, -0.01324112,\n",
       "         -0.02281496, -0.00326099,  0.00914895,  0.00181643,  0.00803294],\n",
       "        [ 0.00936632, -0.01492397,  0.00287683,  0.0196648 , -0.00570533,\n",
       "         -0.02029072, -0.00231905, -0.0046467 ,  0.00418381, -0.00892406,\n",
       "          0.0009073 , -0.02217409,  0.00853963,  0.01586872,  0.01297877,\n",
       "         -0.01515216,  0.00319198, -0.02983969,  0.00283195, -0.0006436 ],\n",
       "        [-0.00991979,  0.00344132,  0.00146335,  0.01027806,  0.00147704,\n",
       "          0.00235455, -0.0194431 , -0.01158497, -0.0047198 ,  0.0029738 ,\n",
       "          0.00096036,  0.01612007, -0.00863923, -0.00215271,  0.00255578,\n",
       "         -0.00231068,  0.00501115, -0.00545726,  0.01545126, -0.00295267],\n",
       "        [ 0.01115941, -0.00030315,  0.01491757, -0.01398246,  0.00516517,\n",
       "         -0.00432585,  0.00231373,  0.01192792, -0.01139212, -0.01322033,\n",
       "         -0.00998298,  0.00254013, -0.01886863,  0.00096739, -0.01286251,\n",
       "         -0.01143712, -0.00369038,  0.00380497, -0.00626715, -0.00492205],\n",
       "        [-0.00041844, -0.00272736, -0.02676522, -0.00430104,  0.0008496 ,\n",
       "          0.01097779,  0.0204633 ,  0.00666988,  0.00079088, -0.00964764,\n",
       "          0.00089053,  0.00778894,  0.01264645, -0.00880511,  0.00236406,\n",
       "          0.00815604,  0.01860809,  0.00255585, -0.00541508, -0.006896  ],\n",
       "        [-0.00357444, -0.0065192 ,  0.00826531,  0.01069236,  0.00724828,\n",
       "          0.01192186, -0.0045377 ,  0.00380333, -0.00384672,  0.00043658,\n",
       "          0.01224941, -0.00029809, -0.01864815, -0.0025282 , -0.0071285 ,\n",
       "         -0.01508918, -0.00790368,  0.00960597,  0.01680823, -0.00489025]]),\n",
       " 'W4': array([[ 0.01002512,  0.01178229, -0.01161396, -0.00039364, -0.17622476,\n",
       "          0.00172387, -0.25955221, -0.00352038,  0.01057818,  0.01262193],\n",
       "        [ 0.01831335, -0.00337523,  0.0186898 ,  0.00665904, -0.18912027,\n",
       "          0.0076161 , -0.24678461,  0.00518434, -0.00102527,  0.01208227]]),\n",
       " 'b1': array([[ -2.21771776e-05],\n",
       "        [  1.90935817e-04],\n",
       "        [  2.75749205e-05],\n",
       "        [  1.31922903e-04],\n",
       "        [ -1.76874045e-05],\n",
       "        [  3.42986346e-05],\n",
       "        [  1.61916439e-05],\n",
       "        [  3.96227465e-05],\n",
       "        [  3.54412123e-05],\n",
       "        [ -1.97735226e-05]]),\n",
       " 'b2': array([[ -9.30518436e-04],\n",
       "        [  1.74684818e-04],\n",
       "        [ -5.84412305e-04],\n",
       "        [  3.33433407e-03],\n",
       "        [  2.28244173e-05],\n",
       "        [ -4.84002727e-04],\n",
       "        [ -6.95334880e-04],\n",
       "        [ -1.07428262e-03],\n",
       "        [ -3.84022489e-04],\n",
       "        [ -3.76977735e-04],\n",
       "        [  5.19633474e-03],\n",
       "        [  6.01756852e-03],\n",
       "        [ -4.47073461e-04],\n",
       "        [  9.46385822e-04],\n",
       "        [ -3.50369733e-04],\n",
       "        [ -6.07913143e-04],\n",
       "        [  1.50735201e-04],\n",
       "        [  3.24103760e-04],\n",
       "        [  5.41776546e-03],\n",
       "        [  8.14180517e-04]]),\n",
       " 'b3': array([[ -3.70943648e-04],\n",
       "        [ -1.12231573e-04],\n",
       "        [ -6.26220466e-05],\n",
       "        [ -1.95660107e-05],\n",
       "        [  2.58052385e-01],\n",
       "        [  1.02167246e-06],\n",
       "        [  3.57662113e-01],\n",
       "        [  1.33715054e-04],\n",
       "        [ -4.21432434e-05],\n",
       "        [ -2.48402066e-04]]),\n",
       " 'b4': array([[-2.79895473],\n",
       "        [-2.79616536]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(test_x, parameters):\n",
    "    return L_model_forward(test_x, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "test_x = np.array([[0.,0.,0.]]).T\n",
    "print(test_x.shape)\n",
    "test_y = [6]\n",
    "predicted_y,cache = predict(test_x, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05033797],\n",
       "       [ 0.05053092]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-5.39372039]), array([-5.3901753]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_yx = predicted_y[0] * (x_max-x_min) + x_min\n",
    "scaled_yy = predicted_y[1] * (y_max-y_min) + y_min\n",
    "(scaled_yx,scaled_yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param2 = np.copy(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'W1': array([[ 0.0177994 ,  0.00426454,  0.000934  ],\n",
       "       [-0.01896168, -0.00296312, -0.00359468],\n",
       "       [-0.00085928, -0.0063077 , -0.00043228],\n",
       "       [-0.00503953, -0.01329157,  0.00890885],\n",
       "       [ 0.00875989,  0.01705744,  0.00049753],\n",
       "       [-0.00412212, -0.0054819 , -0.01547433],\n",
       "       [ 0.00985497, -0.01099701, -0.01186139],\n",
       "       [-0.00201888,  0.01492457,  0.00237502],\n",
       "       [-0.0102983 , -0.00717661,  0.00623851],\n",
       "       [-0.00162964, -0.00764539, -0.00227443]]), 'b1': array([[ -2.21771776e-05],\n",
       "       [  1.90935817e-04],\n",
       "       [  2.75749205e-05],\n",
       "       [  1.31922903e-04],\n",
       "       [ -1.76874045e-05],\n",
       "       [  3.42986346e-05],\n",
       "       [  1.61916439e-05],\n",
       "       [  3.96227465e-05],\n",
       "       [  3.54412123e-05],\n",
       "       [ -1.97735226e-05]]), 'W2': array([[  7.45017086e-03,   1.97225393e-02,  -1.24464765e-02,\n",
       "         -6.29140961e-03,  -8.03782535e-03,  -2.41942840e-02,\n",
       "         -9.23798278e-03,  -1.02437895e-02,   1.12073176e-02,\n",
       "         -1.32487834e-03],\n",
       "       [ -1.62328981e-02,   6.48107218e-03,  -3.56268503e-03,\n",
       "         -1.74314196e-02,  -5.96927658e-03,  -5.87463447e-03,\n",
       "         -8.73862591e-03,   2.98777424e-04,  -2.24811641e-02,\n",
       "         -2.67732484e-03],\n",
       "       [  1.01123652e-02,   8.51874484e-03,   1.10803096e-02,\n",
       "          1.11829434e-02,   1.48464797e-02,  -1.11824285e-02,\n",
       "          8.46329357e-03,  -1.86221832e-02,  -6.04148990e-03,\n",
       "         -1.91466387e-02],\n",
       "       [  1.05331383e-02,   1.34428653e-02,  -1.95373201e-03,\n",
       "          1.78033554e-02,  -6.68707169e-03,   1.56187720e-03,\n",
       "          1.55345570e-03,  -1.06054784e-02,   4.44596276e-03,\n",
       "          1.94186454e-02],\n",
       "       [ -1.02484244e-02,   8.99703248e-03,  -1.54446576e-03,\n",
       "          1.76972002e-02,   4.83905272e-03,   6.76404319e-03,\n",
       "          6.43137311e-03,   2.49128136e-03,  -1.39562379e-02,\n",
       "          1.39176189e-02],\n",
       "       [ -1.37070213e-02,   2.37181035e-03,   6.13962360e-03,\n",
       "         -8.37925457e-03,   1.44883560e-03,   1.16599119e-02,\n",
       "         -2.48653034e-04,  -8.89036349e-03,  -2.91578788e-02,\n",
       "         -9.72114464e-03],\n",
       "       [ -5.91637464e-03,  -5.16875965e-03,  -9.61028336e-03,\n",
       "          3.75996309e-03,  -5.74713057e-03,  -1.11519084e-03,\n",
       "          6.75760418e-03,  -8.55437201e-03,  -3.00813318e-03,\n",
       "          2.15676785e-02],\n",
       "       [  8.69402341e-03,  -1.29365876e-02,  -7.98689030e-04,\n",
       "          5.63952747e-03,   1.22844083e-02,   1.48786595e-03,\n",
       "         -5.31684734e-03,  -7.32714282e-03,   6.44769194e-03,\n",
       "          3.12937257e-03],\n",
       "       [ -5.16224516e-03,  -1.89817331e-03,  -4.16661789e-03,\n",
       "          7.24076602e-03,  -6.89965434e-03,   4.84887036e-03,\n",
       "          8.50411270e-03,   4.86181074e-03,  -8.34714290e-03,\n",
       "          1.34429171e-02],\n",
       "       [ -6.78235000e-03,   4.24753160e-03,  -7.53341372e-03,\n",
       "         -1.74411126e-02,   2.25480732e-03,   2.85764902e-03,\n",
       "         -7.75039436e-04,   2.75249530e-03,  -6.48556812e-03,\n",
       "         -7.37500819e-03],\n",
       "       [ -1.60893650e-03,   1.92568409e-02,   8.17718534e-03,\n",
       "         -5.11429010e-03,   5.68169418e-03,  -4.70170602e-03,\n",
       "         -4.54386111e-03,   8.65788224e-03,  -5.14985873e-03,\n",
       "         -1.67153787e-02],\n",
       "       [ -8.97815408e-03,   1.07699149e-03,   1.31668656e-03,\n",
       "          1.25215460e-02,  -7.05549447e-03,   7.41368024e-03,\n",
       "          4.30092530e-03,  -1.42275596e-03,   8.48184964e-03,\n",
       "          4.97257254e-03],\n",
       "       [ -8.62307488e-03,   1.06963019e-02,  -1.22117617e-02,\n",
       "          5.86094470e-04,   2.54024137e-05,   4.23799426e-03,\n",
       "         -7.25571173e-03,  -3.50685711e-04,  -1.41875741e-03,\n",
       "          9.96716943e-03],\n",
       "       [ -7.93303781e-03,   7.56889182e-04,  -2.61088281e-03,\n",
       "         -1.29761798e-02,   2.67883203e-02,  -6.97690319e-04,\n",
       "         -1.48636743e-02,   1.41050179e-02,  -1.06960175e-02,\n",
       "          3.71168315e-03],\n",
       "       [  8.61213327e-03,  -6.48452788e-03,  -4.30907436e-03,\n",
       "         -5.40397383e-03,  -1.30792866e-03,  -1.62246171e-02,\n",
       "         -1.23575697e-02,  -1.41351508e-03,   1.03889439e-02,\n",
       "          6.31730072e-03],\n",
       "       [  1.72894120e-02,   6.91994577e-03,  -5.11343075e-03,\n",
       "         -1.24392253e-03,  -2.03053291e-02,  -9.60861521e-03,\n",
       "         -1.02043990e-02,   2.70057122e-03,   6.46075263e-03,\n",
       "         -5.60554754e-03],\n",
       "       [ -5.86880746e-03,  -1.54674347e-02,  -1.27620111e-03,\n",
       "          2.48201042e-03,   4.47559250e-03,  -7.82379563e-03,\n",
       "          1.98903038e-02,   1.19562324e-02,  -9.52052639e-04,\n",
       "         -5.26936206e-03],\n",
       "       [ -3.21535745e-03,   1.52152553e-03,  -1.84674187e-04,\n",
       "          4.84065903e-03,   7.69290622e-03,   1.36670916e-02,\n",
       "          1.14736225e-02,  -1.09760999e-03,   3.88894929e-03,\n",
       "         -3.86912795e-03],\n",
       "       [ -5.78875393e-03,   1.92768695e-02,  -4.56623276e-03,\n",
       "          1.99991003e-02,  -3.39066819e-03,   2.61593943e-03,\n",
       "          1.09322808e-02,   3.01567332e-04,   4.03861672e-03,\n",
       "         -2.36849218e-03],\n",
       "       [ -4.74998598e-03,  -1.62625477e-03,  -6.49194241e-03,\n",
       "          1.63289479e-02,  -1.67117641e-03,   1.72410160e-02,\n",
       "         -2.68472841e-02,   1.91278197e-04,   5.63746752e-03,\n",
       "         -2.93099494e-03]]), 'b2': array([[ -9.30518436e-04],\n",
       "       [  1.74684818e-04],\n",
       "       [ -5.84412305e-04],\n",
       "       [  3.33433407e-03],\n",
       "       [  2.28244173e-05],\n",
       "       [ -4.84002727e-04],\n",
       "       [ -6.95334880e-04],\n",
       "       [ -1.07428262e-03],\n",
       "       [ -3.84022489e-04],\n",
       "       [ -3.76977735e-04],\n",
       "       [  5.19633474e-03],\n",
       "       [  6.01756852e-03],\n",
       "       [ -4.47073461e-04],\n",
       "       [  9.46385822e-04],\n",
       "       [ -3.50369733e-04],\n",
       "       [ -6.07913143e-04],\n",
       "       [  1.50735201e-04],\n",
       "       [  3.24103760e-04],\n",
       "       [  5.41776546e-03],\n",
       "       [  8.14180517e-04]]), 'W3': array([[ 0.0109465 ,  0.00639692, -0.00274605,  0.00434907,  0.02811828,\n",
       "         0.00251995,  0.00299499, -0.00439994,  0.0013348 , -0.01289262,\n",
       "        -0.00198352,  0.02457481,  0.01067198,  0.00641416,  0.01103921,\n",
       "         0.01881753,  0.00593586,  0.0207083 ,  0.01069671,  0.00166495],\n",
       "       [ 0.01719475, -0.02359215, -0.0057135 ,  0.00265775, -0.00912095,\n",
       "        -0.00156058, -0.00638795, -0.00654416,  0.02711918,  0.00627474,\n",
       "        -0.00053954,  0.01315139, -0.00237334,  0.00885339,  0.00350816,\n",
       "         0.01626573, -0.01419891,  0.00765714,  0.0012223 , -0.01157377],\n",
       "       [ 0.01065403, -0.00872374,  0.01619287,  0.0051359 ,  0.0069585 ,\n",
       "         0.00080459,  0.00904523, -0.01865655,  0.00074738, -0.00628247,\n",
       "         0.00282815, -0.0004704 ,  0.00616827, -0.0083763 ,  0.01839152,\n",
       "         0.0231584 , -0.00208298, -0.00014717,  0.00287883,  0.01264124],\n",
       "       [ 0.01896901, -0.01205803, -0.00615109, -0.01062156, -0.01112782,\n",
       "        -0.01639296,  0.00362803, -0.01159037,  0.01503262,  0.00908318,\n",
       "        -0.01029711, -0.01030209, -0.00612385,  0.01399962, -0.00849607,\n",
       "        -0.0149355 , -0.00049425,  0.00373389, -0.00657258,  0.01619431],\n",
       "       [ 0.00243221,  0.00453336, -0.00850368,  0.00023569, -0.00141475,\n",
       "        -0.02271918,  0.00288258, -0.01793993, -0.00025774, -0.01473489,\n",
       "         0.02093653,  0.00407214,  0.00865802,  0.00936255, -0.01324112,\n",
       "        -0.02281496, -0.00326099,  0.00914895,  0.00181643,  0.00803294],\n",
       "       [ 0.00936632, -0.01492397,  0.00287683,  0.0196648 , -0.00570533,\n",
       "        -0.02029072, -0.00231905, -0.0046467 ,  0.00418381, -0.00892406,\n",
       "         0.0009073 , -0.02217409,  0.00853963,  0.01586872,  0.01297877,\n",
       "        -0.01515216,  0.00319198, -0.02983969,  0.00283195, -0.0006436 ],\n",
       "       [-0.00991979,  0.00344132,  0.00146335,  0.01027806,  0.00147704,\n",
       "         0.00235455, -0.0194431 , -0.01158497, -0.0047198 ,  0.0029738 ,\n",
       "         0.00096036,  0.01612007, -0.00863923, -0.00215271,  0.00255578,\n",
       "        -0.00231068,  0.00501115, -0.00545726,  0.01545126, -0.00295267],\n",
       "       [ 0.01115941, -0.00030315,  0.01491757, -0.01398246,  0.00516517,\n",
       "        -0.00432585,  0.00231373,  0.01192792, -0.01139212, -0.01322033,\n",
       "        -0.00998298,  0.00254013, -0.01886863,  0.00096739, -0.01286251,\n",
       "        -0.01143712, -0.00369038,  0.00380497, -0.00626715, -0.00492205],\n",
       "       [-0.00041844, -0.00272736, -0.02676522, -0.00430104,  0.0008496 ,\n",
       "         0.01097779,  0.0204633 ,  0.00666988,  0.00079088, -0.00964764,\n",
       "         0.00089053,  0.00778894,  0.01264645, -0.00880511,  0.00236406,\n",
       "         0.00815604,  0.01860809,  0.00255585, -0.00541508, -0.006896  ],\n",
       "       [-0.00357444, -0.0065192 ,  0.00826531,  0.01069236,  0.00724828,\n",
       "         0.01192186, -0.0045377 ,  0.00380333, -0.00384672,  0.00043658,\n",
       "         0.01224941, -0.00029809, -0.01864815, -0.0025282 , -0.0071285 ,\n",
       "        -0.01508918, -0.00790368,  0.00960597,  0.01680823, -0.00489025]]), 'b3': array([[ -3.70943648e-04],\n",
       "       [ -1.12231573e-04],\n",
       "       [ -6.26220466e-05],\n",
       "       [ -1.95660107e-05],\n",
       "       [  2.58052385e-01],\n",
       "       [  1.02167246e-06],\n",
       "       [  3.57662113e-01],\n",
       "       [  1.33715054e-04],\n",
       "       [ -4.21432434e-05],\n",
       "       [ -2.48402066e-04]]), 'W4': array([[ 0.01002512,  0.01178229, -0.01161396, -0.00039364, -0.17622476,\n",
       "         0.00172387, -0.25955221, -0.00352038,  0.01057818,  0.01262193],\n",
       "       [ 0.01831335, -0.00337523,  0.0186898 ,  0.00665904, -0.18912027,\n",
       "         0.0076161 , -0.24678461,  0.00518434, -0.00102527,  0.01208227]]), 'b4': array([[-2.79895473],\n",
       "       [-2.79616536]])}, dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def L_layer_model_reversed(X, Y, params,layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization.\n",
    "    ### START CODE HERE ###\n",
    "    params = initialize_parameters_deep_rev(layers_dims,params)\n",
    "    ### END CODE HERE ###\n",
    "    #parameters = params\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "        #print(i)\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        #print(\"current params\", params)\n",
    "        X = params[\"A0\"]\n",
    "        #print(\"X is\",X)\n",
    "        AL, caches = L_model_forward_inverse(X, params)\n",
    "        ### END CODE HERE ###\n",
    "        #print(\"AL\", AL,Y)\n",
    "        \n",
    "        # Compute cost.\n",
    "        \n",
    "        cost = compute_cost(AL, Y)\n",
    "        #print(\"cost\", cost)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        ### END CODE HERE ###\n",
    "        for key in list(grads):\n",
    "            if key.startswith(\"dW\") or key.startswith(\"db\"):\n",
    "                #print(\"grads are\", key)\n",
    "                grads.pop(key,None)\n",
    "    \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        params = update_parameters_reversed(params, grads, learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        #print(\"grads\", grads)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "  \n",
    "    \n",
    "    return params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_reversed(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "\n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters\n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters\n",
    "                  parameters[\"W\" + str(l)] = ...\n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "\n",
    "    L = len(parameters) // 2  # number of layers in the neural network\n",
    "    #print(\"L is \", L, parameters)\n",
    "    #print(\"grads is \", L, grads)\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    ### START CODE HERE ### (˜ 3 lines of code)\n",
    "    for l in range(L-2):\n",
    "        #print(l,parameters[\"A\" + str(l )].shape,grads[\"dA\" + str(l + 1)])\n",
    "        #print(\"dA\" + str(l + 1) , \" applied\")\n",
    "        parameters[\"A\" + str(l )] = parameters[\"A\" + str(l )] - learning_rate * grads[\"dA\" + str(l + 1)]\n",
    "       # parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "    ### END CODE HERE ###\n",
    "    #print(\"L is \", L, grads)\n",
    "    #parameters[\"A\" + str(L-2)] = parameters[\"A\" + str(L-2 )] - learning_rate * grads[\"dA\" + str(L-2)]\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters_deep_rev(layer_dims,parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(3)\n",
    "    #parameters = {}\n",
    "    L = len(layer_dims)  # number of layers in the network\n",
    "\n",
    "    for l in range(0, L):\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        #parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * 0.01\n",
    "        parameters['A' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        #assert (parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
    "        #assert (parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "    \n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_model_forward_inverse(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "\n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "\n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, 4):\n",
    "        A_prev = A \n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        #print(\"l is\", l)\n",
    "        A, cache = linear_activation_forward(A_prev, \n",
    "                                             parameters['W' + str(l)], \n",
    "                                             parameters['b' + str(l)], \n",
    "                                             activation='relu')\n",
    "        caches.append(cache)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    L=4\n",
    "    AL, cache = linear_activation_forward(A, \n",
    "                                          parameters['W' + str(L)], \n",
    "                                          parameters['b' + str(L)], \n",
    "                                          activation='sigmoid')\n",
    "    caches.append(cache)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #print(AL.shape, (2, X.shape[1]) )\n",
    "    assert(AL.shape == (2, X.shape[1]))\n",
    "            \n",
    "    return AL, caches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 17.703407\n",
      "Cost after iteration 100: 15.339295\n",
      "Cost after iteration 200: 14.094039\n",
      "Cost after iteration 300: 12.813511\n",
      "Cost after iteration 400: 11.543576\n",
      "Cost after iteration 500: 10.326279\n",
      "Cost after iteration 600: 9.082035\n",
      "Cost after iteration 700: 7.853533\n",
      "Cost after iteration 800: 6.681087\n",
      "Cost after iteration 900: 5.488531\n",
      "Cost after iteration 1000: 4.343069\n",
      "Cost after iteration 1100: 3.202485\n",
      "Cost after iteration 1200: 2.073822\n",
      "Cost after iteration 1300: 1.002532\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nicv/A8RzQUahthH7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117581588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X1 = np.array([[0.,0.,0.]]).T\n",
    "Y1 = np.array([[0.,6.]]).T\n",
    "P=L_layer_model_reversed(X1,Y1,parameters,layers_dims,learning_rate = 10e9,print_cost=True,num_iterations = 1350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_inputs = P[\"A0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10345061.79140309],\n",
       "       [ 10904019.55644543],\n",
       "       [   104932.2233483 ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
