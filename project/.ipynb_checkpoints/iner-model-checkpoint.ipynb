{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [0, 1, 2, 3, 4, 5, 'cat']\n",
    "\n",
    "df = pd.DataFrame(columns=cols)\n",
    "filedir = './Inertial/'\n",
    "\n",
    "for file in os.listdir(filedir):\n",
    "    \n",
    "    if not file.startswith(\".\"):\n",
    "        # import matlab file into df with label\n",
    "        data = loadmat(filedir + file)\n",
    "        df1 = pd.DataFrame(data['d_iner'])\n",
    "\n",
    "        category = file.split('_')[0]\n",
    "        subcat = str(file.split('_')[0] + '_' + file.split('_')[1] + '_' + file.split('_')[2])\n",
    "        df1['cat'] = category\n",
    "\n",
    "        # append to original df\n",
    "        df = df.append(df1)\n",
    "\n",
    "        print('appended {}!'.format(subcat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(filedir):\n",
    "    \n",
    "    if not file.startswith(\".\"):\n",
    "        df_{}.format(file) = pd.DataFrame(loadmat(filedir + file)['d_iner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 classes only\n",
    "vids = ['a1', 'a2', 'a3']\n",
    "\n",
    "# subsetting df\n",
    "df = df[df['cat'].isin(vids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.iloc[:, 0:6]\n",
    "Y = df.cat\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, Y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "DO NOT RUN THIS CODE CHUNK!!!\n",
    "\n",
    "SVM tuning takes up a considerable amount of time.\n",
    "Load the SVM pickle (see below chunk) for prediction instead!\n",
    "\n",
    "'''\n",
    "\n",
    "# svc parameter tuning\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    \n",
    "    grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    \n",
    "    return grid_search.best_params_\n",
    "\n",
    "best_params = svc_param_selection(X_train, Y_train, nfolds=5)\n",
    "\n",
    "# best cost and gamma for svc\n",
    "best_cost = best_params['C']\n",
    "best_gam = best_params['gamma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fname = 'clf_iner_svc.pkl'\n",
    "\n",
    "# pickling classifier\n",
    "#with open(fname, 'wb') as handle:\n",
    "#    pickle.dump(clf_svc, handle)\n",
    "\n",
    "# loading pickle\n",
    "with open('clf_iner_svc.pkl', 'rb') as handle:\n",
    "    clf_svc = pickle.load(handle)\n",
    "\n",
    "# svc training\n",
    "# clf_svc = SVC(C=best_cost, gamma=best_gam)\n",
    "clf_svc.fit(X_train, Y_train)\n",
    "\n",
    "# svc prediction\n",
    "Y_pred_svc = clf_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class report, cm and accuracy\n",
    "print(classification_report(Y_test, Y_pred_svc), end='\\n\\n')\n",
    "print(confusion_matrix(Y_test, Y_pred_svc), end='\\n\\n')\n",
    "print('acc: {0:.3f}%'.format(accuracy_score(Y_test, Y_pred_svc)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "# train\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded_Y_train = encoder.transform(Y_train)\n",
    "\n",
    "# test\n",
    "encoder.fit(Y_test)\n",
    "encoded_Y_test = encoder.transform(Y_test)\n",
    "\n",
    "\n",
    "# convert integers to dummy variables, ie. one-hot encoding\n",
    "# train\n",
    "dummy_Y_train = np_utils.to_categorical(encoded_Y_train)\n",
    "\n",
    "# test\n",
    "dummy_Y_test = np_utils.to_categorical(encoded_Y_test)\n",
    "\n",
    "# convert X to np array\n",
    "X_train_np = np.reshape(X_train.values, (11004,6))\n",
    "X_test_np = np.reshape(X_test.values, (4717,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(123)\n",
    "\n",
    "# building the model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=6, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.005), metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train_np, dummy_Y_train, epochs=100, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "dummy_Y_pred = model.predict(X_test_np)\n",
    "\n",
    "Y_test_class = np.argmax(dummy_Y_test, axis=1)\n",
    "Y_pred_class = np.argmax(dummy_Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "scores = model.evaluate(X_test_np, dummy_Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(classification_report(Y_test_class, Y_pred_class), end='\\n\\n')\n",
    "print(confusion_matrix(Y_test_class, Y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import warnings\n",
    "from hmmlearn.hmm import GaussianHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inertial_data():\n",
    "    dir_path = \"Inertial\"\n",
    "    files = os.listdir(dir_path)\n",
    "    all_data = [] \n",
    "    for ii, file in enumerate(files, 1):\n",
    "        #print(ii, file)\n",
    "        if file.endswith(\".mat\"):\n",
    "            mat_contents = loadmat(dir_path+'/'+file)\n",
    "            d_skel=mat_contents[\"d_iner\"]\n",
    "            action = file.split(\"_\")[0]\n",
    "            all_data.append((d_skel,action))\n",
    "    print(len(all_data))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(all_data, all_actions,split_at):\n",
    "    ddct = defaultdict(list)\n",
    "    training_data=[]\n",
    "    testing_data=[]\n",
    "    for X,y in all_data:\n",
    "        for action in all_actions:\n",
    "            if(action == y):\n",
    "                ddct[action].append(1)\n",
    "                if len(ddct[action]) < split_at+1:\n",
    "                    training_data.append((X,y))\n",
    "                else:\n",
    "                    testing_data.append((X,y))\n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'a10', 'a11', 'a12', 'a13', 'a14', 'a15', 'a16', 'a17', 'a18', 'a19', 'a20', 'a21', 'a22', 'a23', 'a24', 'a25', 'a26', 'a27']\n"
     ]
    }
   ],
   "source": [
    "all_actions=[\"a\"+str(num) for num in range(1,28)]\n",
    "print(all_actions)\n",
    "\n",
    "split_at = 26 #as each data contains 32 records so 26 for training and 6 for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861\n"
     ]
    }
   ],
   "source": [
    "all_data_iner = load_inertial_data()\n",
    "training_data_iner, testing_data_iner = split_data(all_data_iner,all_actions,26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training.. 702\n",
      "testing.. 159\n"
     ]
    }
   ],
   "source": [
    "print(\"training..\" , len(training_data_iner))\n",
    "print(\"testing..\" , len(testing_data_iner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_training_data_by_action(records,action):\n",
    "    action_pairs=[]\n",
    "    for X,y in records:\n",
    "        if y == action:\n",
    "            action_pairs.append((X,y))\n",
    "    return action_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_an_action(action, num_hidden_states, features,lengths):\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  \n",
    "    model = GaussianHMM(n_components=num_hidden_states, n_iter=1000,random_state=123,params=\"ct\").fit(features,lengths)\n",
    "    logL = model.score(features,lengths)\n",
    "    return model, logL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hmm_formatted_features_inertial(records,action):\n",
    "    x_contatinated = np.zeros((1,6))\n",
    "    lengths=[]\n",
    "    \n",
    "    actions = fetch_training_data_by_action(records,action)\n",
    "    action_features,_ = zip(*actions)\n",
    "    print(len(action_features))\n",
    "    print(action_features[0].shape)\n",
    "    \n",
    "    \n",
    "    for subject_action in list(action_features):\n",
    "        lengths.append(subject_action.shape[0])\n",
    "        x_contatinated = np.append(x_contatinated,subject_action,axis=0)\n",
    "#         x_contatinated.append(subject_action)\n",
    "#         for i in range(subject_action.shape[1]):\n",
    "#             x_contatinated.append(subject_action) #subject_action[:,:,i].reshape(-1,))\n",
    "    #len(x_contatinated)\n",
    "    print(x_contatinated[0])\n",
    "    print(x_contatinated[1])\n",
    "    x_contatinated = np.delete(x_contatinated, 0, axis=0)\n",
    "    print(np.array(x_contatinated).shape)\n",
    "    print(x_contatinated[0])\n",
    "    print(x_contatinated[1])\n",
    "    print(lengths)\n",
    "    return np.array(x_contatinated),lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "(160, 6)\n",
      "[ 0.  0.  0.  0.  0.  0.]\n",
      "[-0.959473 -0.177734 -0.192871  5.221374  1.526718  0.152672]\n",
      "(4150, 6)\n",
      "[-0.959473 -0.177734 -0.192871  5.221374  1.526718  0.152672]\n",
      "[-0.961914 -0.15332  -0.159912  6.778626  1.954198  0.244275]\n",
      "[160, 154, 165, 158, 142, 156, 143, 157, 146, 127, 125, 150, 145, 143, 142, 160, 186, 170, 190, 180, 187, 180, 183, 189, 149, 163]\n"
     ]
    }
   ],
   "source": [
    "iner_X,iner_lengths = get_hmm_formatted_features_inertial(training_data_iner,'a1')\n",
    "iner_model, iner_logL = train_an_action('a1', 3, iner_X ,iner_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states trained in model for a1 is 3\n",
      "logL = -74799.60789966404\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of states trained in model for {} is {}\".format('a1', iner_model.n_components))\n",
    "print(\"logL = {}\".format(iner_logL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
